# HomebrewNLP

## Overview

A case study of efficient training of large language models using commodity hardware.

## Example Command

```BASH
python3 main.py train --config_path configs/small.yaml
```

---
[![DeepSource](https://deepsource.io/gh/HomebrewNLP/HomebrewNLP.svg/?label=active+issues&show_trend=true&token=sAQ42SRyNPilkjj82sQd88ea)](https://deepsource.io/gh/HomebrewNLP/HomebrewNLP/?ref=repository-badge)
| [Discord](https://discord.gg/JSGG6Abcyx)
| [WandB](https://wandb.ai/homebrewnlp/gpt)

## Datasets
* [Book Dataset](https://drive.google.com/file/u/1/d/1aoW3KI2E3nK7B28RE6I6_oDtNidTvoc2/view?usp=sharing)
* [200MB Slice](https://drive.google.com/file/d/1QTbRYe-BOq2kw8foWB16NGPthQjZr7yn/view?usp=sharing) of [ThePile](https://github.com/EleutherAI/the-pile)
